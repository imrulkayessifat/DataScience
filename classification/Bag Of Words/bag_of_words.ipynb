{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bag_of_words.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "llD6awndeEbK"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4ewcUyvehou"
      },
      "source": [
        "data_imdb = r\"https://drive.google.com/file/d/1QtSgzb9eF0cqXBd0cFLpDlBG9LfBh5UK/view?usp=sharing\"\n",
        "data_imdb = r\"https://drive.google.com/uc?id=\" + data_imdb.split('/')[-2]\n",
        "data_imdb = pd.read_csv(data_imdb,delimiter='\\t',header=None)\n",
        "data_imdb.columns = [\"Review_text\",\"Review class\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fNs_PaafWLi"
      },
      "source": [
        "data_amazon = r\"https://drive.google.com/file/d/1czEh8Ga2Uo2omdeMZECbQsjtKFqomq1O/view?usp=sharing\"\n",
        "data_amazon = r\"https://drive.google.com/uc?id=\" + data_amazon.split('/')[-2]\n",
        "data_amazon = pd.read_csv(data_amazon,delimiter='\\t',header=None)\n",
        "data_amazon.columns = [\"Review_text\",\"Review class\"]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPnkl8_FfrRx"
      },
      "source": [
        "data_yelp = r\"https://drive.google.com/file/d/1_ev3N05EjCy3P3vm5D_nSSG9GlTf2uDJ/view?usp=sharing\"\n",
        "data_yelp = r\"https://drive.google.com/uc?id=\" + data_yelp.split('/')[-2]\n",
        "data_yelp = pd.read_csv(data_yelp,delimiter='\\t',header=None)\n",
        "data_yelp.columns = [\"Review_text\",\"Review class\"]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0iY9rBagCwM"
      },
      "source": [
        "data = pd.concat([data_imdb,data_amazon,data_yelp])\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4WkhysBhA0j"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCS1y485hKMZ"
      },
      "source": [
        "def clean_text(df):\n",
        "    all_reviews = list()\n",
        "    lines = df[\"Review_text\"].values.tolist()\n",
        "    for text in lines:\n",
        "        text = text.lower()\n",
        "        pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "        text = pattern.sub('', text)\n",
        "        text = re.sub(r\"[,.\\\"!@#$%^&*(){}?/;`~:<>+=-]\", \"\", text)\n",
        "        tokens = word_tokenize(text)\n",
        "        table = str.maketrans('', '', string.punctuation)\n",
        "        stripped = [w.translate(table) for w in tokens]\n",
        "        words = [word for word in stripped if word.isalpha()]\n",
        "        stop_words = set(stopwords.words(\"english\"))\n",
        "        stop_words.discard(\"not\")\n",
        "        PS = PorterStemmer()\n",
        "#         words = [w for w in words if not w in stop_words]\n",
        "        words = [PS.stem(w) for w in words if not w in stop_words]\n",
        "        words = ' '.join(words)\n",
        "        all_reviews.append(words)\n",
        "    return all_reviews\n",
        "\n",
        "all_reviews = clean_text(data)\n",
        "all_reviews[0:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfnJDHupifRi"
      },
      "source": [
        "stopwords.words(\"english\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH9m3Is1i8DJ"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "CV = CountVectorizer(min_df=3)   \n",
        "X = CV.fit_transform(all_reviews).toarray()\n",
        "y = data['Review class'].values\n",
        "print(np.shape(X))\n",
        "print(np.shape(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWKXR2u6kTw0",
        "outputId": "68b4b831-36a4-4be5-c964-9c9ae1ed1fac"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# model = DecisionTreeClassifier(criterion=\"entropy\", random_state=41)\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB()\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(f1_score(y_test, y_pred))\n",
        "print(precision_score(y_test, y_pred))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6618181818181819\n",
            "0.7038216560509554\n",
            "0.6314285714285715\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}